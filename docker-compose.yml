services:
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: nda-ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #     - OLLAMA_CONTEXT_LENGTH=${OLLAMA_CONTEXT_LENGTH}
  #     - OLLAMA_NUM_PARALLEL=1
  #     - OLLAMA_NUM_THREAD=1
  #     - OLLAMA_KEEP_ALIVE=5m
  #     - CUDA_VISIBLE_DEVICES=0
  #     - NVIDIA_VISIBLE_DEVICES=0
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ['0']
  #             capabilities: [gpu]
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://127.0.0.1:11434/api/version"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  postgres:
    image: postgres:15-alpine
    container_name: nda-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-nda_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-nda_password}
      POSTGRES_DB: ${POSTGRES_DB:-nda_db}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-nda_user}"]
      interval: 10s
      timeout: 5s
      retries: 5

  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: nda-opensearch
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - "OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_PASS:-admin123}"
      - "OPENSEARCH_USERNAME=${OPENSEARCH_USER:-admin}"
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.7.0
    container_name: nda-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "timeout 5s bash -c '</dev/tcp/localhost/6333 || exit 1' || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  minio:
    image: minio/minio:latest
    container_name: nda-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-minioadmin}
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 5

  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    container_name: nda-api
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - POSTGRES_URL=postgresql://${POSTGRES_USER:-nda_user}:${POSTGRES_PASSWORD:-nda_password}@postgres:5432/${POSTGRES_DB:-nda_db}
      - OPENSEARCH_URL=http://opensearch:9200
      - OPENSEARCH_USER=${OPENSEARCH_USER:-admin}
      - OPENSEARCH_PASS=${OPENSEARCH_PASS:-admin123}
      - QDRANT_URL=http://qdrant:6333
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-mpnet-base-v2}
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama_local}
      - LLM_ENDPOINT=${LLM_ENDPOINT:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_CONVERSATION_MODEL=${OLLAMA_CONVERSATION_MODEL:-}
      - OLLAMA_CONTEXT_LENGTH=${OLLAMA_CONTEXT_LENGTH}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-24h}
      - ENABLE_LLM_REFINEMENT=${ENABLE_LLM_REFINEMENT:-false}
      - LLM_EXTRACTION_MODEL=${LLM_EXTRACTION_MODEL}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - USE_TEXTRACT=${USE_TEXTRACT:-false}
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      opensearch:
        condition: service_healthy
      qdrant:
        condition: service_started
      minio:
        condition: service_healthy
      # ollama:
      #   condition: service_healthy
      model_preloader:
        condition: service_completed_successfully
    volumes:
      - ./api:/app/api
      - ./ingest:/app/ingest
      - ./llm:/app/llm
      - ./ontology:/app/ontology
      - ./scripts:/app/scripts
      - ./eval:/app/eval:ro
      - ./.cache/huggingface:/root/.cache/huggingface
      - ./data:/app/data:ro
      - ./docs:/app/docs:ro

  ingest:
    build:
      context: .
      dockerfile: ingest/Dockerfile
    container_name: nda-ingest
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - POSTGRES_URL=postgresql://${POSTGRES_USER:-nda_user}:${POSTGRES_PASSWORD:-nda_password}@postgres:5432/${POSTGRES_DB:-nda_db}
      - OPENSEARCH_URL=http://opensearch:9200
      - OPENSEARCH_USER=${OPENSEARCH_USER:-admin}
      - OPENSEARCH_PASS=${OPENSEARCH_PASS:-admin123}
      - QDRANT_URL=http://qdrant:6333
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-mpnet-base-v2}
      - USE_TEXTRACT=${USE_TEXTRACT:-false}
      - ENABLE_LLM_REFINEMENT=${ENABLE_LLM_REFINEMENT:-false}
      - LLM_ENDPOINT=${LLM_ENDPOINT:-http://ollama:11434}
      - LLM_EXTRACTION_MODEL=${LLM_EXTRACTION_MODEL}
    depends_on:
      postgres:
        condition: service_healthy
      opensearch:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./ingest:/app/ingest
      - ./api:/app/api
      - ./ontology:/app/ontology
      - ./scripts:/app/scripts
      - ./.cache/huggingface:/root/.cache/huggingface
      - ./data:/app/data:ro
      - ./docs:/app/docs:ro

  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: nda-ui
    environment:
      # Use Cloudflare tunnel API domain if set, otherwise fallback to localhost
      # The UI code will prepend https:// if the domain doesn't start with http
      - NEXT_PUBLIC_API_URL=${CLOUDFLARE_DOMAIN_API:-http://localhost:8000}
    ports:
      - "3000:3000"
    depends_on:
      - api
    volumes:
      - ./ui:/app
      - /app/node_modules
      - /app/.next
    command: npm run dev

  model_preloader:
    build:
      context: .
      dockerfile: api/Dockerfile
    container_name: nda-model-preloader
    environment:
      - LLM_ENDPOINT=${LLM_ENDPOINT:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_CONVERSATION_MODEL=${OLLAMA_CONVERSATION_MODEL:-}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-24h}
    command: python3 /app/scripts/preload_ollama_models.py
    depends_on:
      # ollama:
      #   condition: service_healthy
    volumes:
      - ./scripts:/app/scripts
      - ./api:/app/api
      - ./llm:/app/llm
    restart: "no"  # Only run once at startup

  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: nda-cloudflared
    # Using config file for ingress rules (CLI control)
    # Alternative: use token-based auth by changing command to: tunnel run
    # and uncommenting TUNNEL_TOKEN environment variable
    command: tunnel --config /etc/cloudflared/config.yml run
    depends_on:
      - ui
      - api
    restart: unless-stopped
    networks:
      - default
    volumes:
      - ./cloudflare/config.yml:/etc/cloudflared/config.yml:ro
      - ./cloudflare/credentials.json:/etc/cloudflared/credentials.json:ro
    # Uncomment below if using token-based auth instead of config file:
    # environment:
    #   - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN:-}

volumes:
  # ollama_data:
  postgres_data:
  opensearch_data:
  qdrant_data:
  minio_data:

# IMPORTANT: Data Persistence
# ---------------------------
# This docker-compose.yml uses named volumes for data persistence:
# - postgres_data: Database (documents, metadata, chunks)
# - minio_data: Object storage (uploaded files)
# - opensearch_data: Search indices
# - qdrant_data: Vector embeddings
# - ollama_data: LLM models (currently disabled)
#
# Data persists across container restarts.
# To preserve data, use: docker compose restart
# To remove data: docker compose down -v (WARNING: deletes all data)
