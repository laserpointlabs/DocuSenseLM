# Model Comparison Test Report

**Generated:** 2025-11-07T13:37:05.718640

## Executive Summary

| Model | Pass Rate | Avg Confidence | Avg Time (ms) | Avg Gen Time (ms) | Avg Eval Time (ms) |
|-------|-----------|----------------|---------------|-------------------|-------------------|
| **mistral:7b** | 90.0% (45/50) | 0.918 | 4650 | 2625 | 2025 |
| **granite3.3:8b** | 90.0% (45/50) | 0.914 | 3735 | 2048 | 1687 |
| **llama3.2:3b** | 84.0% (42/50) | 0.818 | 4118 | 2152 | 1966 |

## Detailed Performance Metrics

### Correctness Comparison


#### mistral:7b
- **Pass Rate:** 90.0% (45/50)
- **Failed:** 5/50
- **Average Confidence:** 0.918

**Category Breakdown:**
- Effective Date: 66.7% (6/9)
- Expiration Date: 88.9% (8/9)
- Governing Law: 88.9% (8/9)
- Location: 100.0% (2/2)
- Mutual Status: 100.0% (6/6)
- Parties: 100.0% (6/6)
- Term: 100.0% (9/9)

#### granite3.3:8b
- **Pass Rate:** 90.0% (45/50)
- **Failed:** 5/50
- **Average Confidence:** 0.914

**Category Breakdown:**
- Effective Date: 88.9% (8/9)
- Expiration Date: 66.7% (6/9)
- Governing Law: 100.0% (9/9)
- Location: 100.0% (2/2)
- Mutual Status: 83.3% (5/6)
- Parties: 100.0% (6/6)
- Term: 100.0% (9/9)

#### llama3.2:3b
- **Pass Rate:** 84.0% (42/50)
- **Failed:** 8/50
- **Average Confidence:** 0.818

**Category Breakdown:**
- Effective Date: 66.7% (6/9)
- Expiration Date: 88.9% (8/9)
- Governing Law: 88.9% (8/9)
- Location: 100.0% (2/2)
- Mutual Status: 66.7% (4/6)
- Parties: 100.0% (6/6)
- Term: 88.9% (8/9)


### Speed Comparison

| Model | Avg Total Time | Avg Generation | Avg Evaluation | Speed Rank |
|-------|----------------|----------------|----------------|------------|
| granite3.3:8b | 3735ms | 2048ms | 1687ms | #1 |
| llama3.2:3b | 4118ms | 2152ms | 1966ms | #2 |
| mistral:7b | 4650ms | 2625ms | 2025ms | #3 |

### Confidence Score Comparison

| Model | Avg Confidence | Confidence Rank |
|-------|----------------|-----------------|
| mistral:7b | 0.918 | #1 |
| granite3.3:8b | 0.914 | #2 |
| llama3.2:3b | 0.818 | #3 |

## Overall Rankings

### Best Overall Performance (Pass Rate + Confidence)
1. **mistral:7b** (Score: 1.000)
2. **granite3.3:8b** (Score: 0.998)
3. **llama3.2:3b** (Score: 0.916)


### Fastest Model
1. **granite3.3:8b** (3735ms avg)

### Highest Confidence
1. **mistral:7b** (0.918 avg)

## Recommendations


- **Best Overall:** mistral:7b - Best balance of correctness and confidence
- **Fastest:** granite3.3:8b - Best for low-latency applications
- **Most Confident:** mistral:7b - Best for high-confidence requirements

### Model-Specific Notes


#### Granite 3.3:8b
- Supports 128K context window (tested with 32K for comparison)
- Has "thinking" mode capability for improved reasoning
- Optimized for RAG and instruction-following tasks
- See: https://ollama.com/library/granite3.3


## Test Configuration

- **Total Questions:** 50
- **Models Tested:** llama3.2:3b, mistral:7b, granite3.3:8b
- **Evaluation Method:** LLM-based semantic evaluation
- **Context Length:** 8K-32K (model-dependent)

## Raw Results

Full detailed results are available in the JSON output file.

---
*Report generated by Model Comparison Test Suite*
